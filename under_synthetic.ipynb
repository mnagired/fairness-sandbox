{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5e91243",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-08T20:41:26.879421Z",
     "start_time": "2021-06-08T20:41:26.876140Z"
    }
   },
   "source": [
    "# Under-Representation Bias (w/ Synthetic Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00909876",
   "metadata": {},
   "source": [
    "This notebook recreates the finding that Equalized Odds constrained model can recover from under-representation bias."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a42ced1",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "Please run the code block below to install the necessary packages (if needed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a692724",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-10T20:42:02.586362Z",
     "start_time": "2021-06-10T20:42:02.581026Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "\n",
    "from sklearn.base import clone\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, roc_curve, auc\n",
    "from collections import Counter\n",
    "\n",
    "import fairlearn\n",
    "from fairlearn.metrics import *\n",
    "from fairlearn.reductions import *\n",
    "import aif360\n",
    "\n",
    "import copy, random\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da59e303",
   "metadata": {},
   "source": [
    "# Synthetic Dataset Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d46dc53-d064-4c1f-8845-891216d77cde",
   "metadata": {},
   "source": [
    "## Parameters (User Input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e4c1bcf-a112-4a4f-9d02-a6724a2268b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "r is the proportion of training examples in the minority group, \n",
    "\n",
    "which means 1-r is proportion of examples in the majority group\n",
    "\n",
    "eta is the probability of flipping the label\n",
    "\n",
    "n is the number of training examples\n",
    "\n",
    "beta is the probability of keeping a positively labeled example\n",
    "from the minority class\n",
    "\n",
    "NOTE: results can be replicated if and only if the following condition holds:\n",
    "\n",
    "(1-r)(1-2*eta) + r((1-eta)*beta - eta) > 0\n",
    "\n",
    "'''\n",
    "def get_params(r = 1/3, eta = 1/4, n = 2000, beta = 0.5):\n",
    "    return r, eta, n, beta\n",
    "\n",
    "r, eta, n, beta = get_params(eta = 0, n = 30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e7d3c98-54c3-4198-9f03-528bebb016cc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "constraint:  1.0\n",
      "yes! 0.3333333333333333 0 1.0\n",
      "constraint:  0.9666666666666668\n",
      "yes! 0.3333333333333333 0 0.9\n",
      "constraint:  0.9333333333333333\n",
      "yes! 0.3333333333333333 0 0.8\n",
      "constraint:  0.9\n",
      "yes! 0.3333333333333333 0 0.7\n",
      "constraint:  0.8666666666666667\n",
      "yes! 0.3333333333333333 0 0.6\n",
      "constraint:  0.8333333333333334\n",
      "yes! 0.3333333333333333 0 0.5\n",
      "constraint:  0.8\n",
      "yes! 0.3333333333333333 0 0.4\n",
      "constraint:  0.7666666666666667\n",
      "yes! 0.3333333333333333 0 0.3\n",
      "constraint:  0.7333333333333334\n",
      "yes! 0.3333333333333333 0 0.2\n",
      "constraint:  0.7000000000000001\n",
      "yes! 0.3333333333333333 0 0.1\n",
      "constraint:  0.6666666666666667\n",
      "yes! 0.3333333333333333 0 0.0\n"
     ]
    }
   ],
   "source": [
    "# check if above constraint holds\n",
    "def check_constraints(r, eta, beta):\n",
    "    first = (1-r)*(1-2*eta)\n",
    "    second = r * ((1-eta)*beta - eta)\n",
    "    res = first + second\n",
    "    print(\"constraint: \", res)\n",
    "    print(\"yes!\", r, eta, beta) if res > 0 else print(\"no\", r, eta, beta)\n",
    "    \n",
    "bias_amts = np.divide(list(range(10, -1, -1)),10)\n",
    "\n",
    "for beta in bias_amts:\n",
    "    check_constraints(r=r, eta=eta, beta=beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270ebbd2-719c-42d5-8de4-dce388fc0a51",
   "metadata": {},
   "source": [
    "## True Label Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74f9b8a4-c293-4c8a-9c8c-72d28f624312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create minority and majority groups\n",
    "def get_cat_features(n, r):\n",
    "    num_minority = int(r * n)\n",
    "    num_majority = n - num_minority\n",
    "    \n",
    "    minority = np.zeros((num_minority, 1))\n",
    "    majority = np.ones((num_majority, 1))\n",
    "    \n",
    "    cat_features = np.vstack((minority, majority))\n",
    "    #np.random.shuffle(cat_features) # this is what causes us to not recover coeffs\n",
    "    \n",
    "    return cat_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acba1061-c071-4a58-ae21-706122184dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# return labels from Bayes Optimal Classifier\n",
    "def get_bayes_optimal_labels(features, effect_param):\n",
    "    outcome_continuous = 1/(1+np.exp(-np.matmul(features, effect_param)))\n",
    "    #return [np.random.binomial(n = 1, p = outcome_continuous[i]) for i in range(len(outcome_continuous))]\n",
    "    return np.random.binomial(1,outcome_continuous) # bernoulli to simulate LR's probabilistic nature\n",
    "\n",
    "# flip labels with probability eta\n",
    "def flip_labels(df_synthetic, eta):\n",
    "    labels = df_synthetic['outcome']\n",
    "    \n",
    "    for i in range(len(labels)):\n",
    "        if random.uniform(0,1) <= eta:\n",
    "            labels[i] = 1 if labels[i] == 0 else 0\n",
    "    df_synthetic['outcome'] = labels\n",
    "    \n",
    "    return df_synthetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9faebb17-ed24-453b-a179-16933179c612",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "create synthetic data with:\n",
    "    3 numerical features (Gaussian), 1 categorical (sensitive attribute) \n",
    "    logistic outcome model s.t. outcome = Indicator[logit(effect_param*features) >= 0.5]\n",
    "    \n",
    "create minority/majority groups according to r param\n",
    "\n",
    "simulate Bayes Optimal Classifiers for minority and majority\n",
    "\n",
    "flip labels according to eta param\n",
    "\n",
    "ensure equal base rates (proportion of positive examples) across both groups\n",
    "\n",
    "'''\n",
    "\n",
    "def true_label_generation(r, eta, n):\n",
    "\n",
    "    ''' \n",
    "    delete this variable to allow user to control percentage of positively labeled examples\n",
    "    eg: let outcome_continuous >= 0.2 implies 80% positively labeled samples\n",
    "    '''\n",
    "    # causal effect params\n",
    "    effect_param_min = [0.5, -0.2, 0.1] \n",
    "    effect_param_maj = [-0.7, 0.5, 1.5]\n",
    "    \n",
    "    num_min = int(n*r)\n",
    "    num_maj = n - num_min\n",
    "\n",
    "    # required: len(cat_probabilities) = n_cat_features\n",
    "    n_cat_features = 2\n",
    "    cat_probabilities = [0.5, 0.5] \n",
    "\n",
    "    # numerical feature params\n",
    "    means = [0, 0, 0]\n",
    "    cov_matrix = [[1, 0, 0], [0, 1, 0], [0, 0, 1]]\n",
    "\n",
    "    # features\n",
    "    cat_features = get_cat_features(r=r, n=n)\n",
    "    \n",
    "    num_features_min = np.random.multivariate_normal(means, cov_matrix, num_min)\n",
    "    #num_features_min = np.random.normal(0, 1, num_min)\n",
    "    num_features_maj = np.random.multivariate_normal(means, cov_matrix, num_maj)\n",
    "    #num_features_min = np.random.normal(0, 1, num_min)\n",
    "\n",
    "    num_features = np.concatenate((num_features_min, num_features_maj))\n",
    "\n",
    "    # outcomes\n",
    "    outcome_binary_min = get_bayes_optimal_labels(features=num_features_min, effect_param=effect_param_min)\n",
    "    #outcome_binary_min = np.where(np.matmul(num_features_min, effect_param_min) > 0.5, 1, 0)\n",
    "    outcome_binary_maj = get_bayes_optimal_labels(features=num_features_maj, effect_param=effect_param_maj)\n",
    "    #outcome_binary_maj = np.where(np.matmul(num_features_maj, effect_param_maj) > 0.5, 1, 0)\n",
    "    \n",
    "    outcome = np.hstack((outcome_binary_min,outcome_binary_maj)).reshape(n,1)\n",
    "    temp_data = np.hstack((num_features,cat_features, outcome))\n",
    "    np.random.shuffle(temp_data) # randomly shuffle the data\n",
    "    \n",
    "    df_synthetic = pd.DataFrame(temp_data)\n",
    "    df_synthetic.columns = ['num1','num2','num3','cat','outcome']\n",
    "    \n",
    "    df_majority = df_synthetic[df_synthetic['cat'] == 1]\n",
    "    df_minority = df_synthetic[df_synthetic['cat'] == 0]\n",
    "    \n",
    "    df_synthetic = flip_labels(df_synthetic, eta)\n",
    "    \n",
    "    return df_synthetic \n",
    "\n",
    "df_synthetic = true_label_generation(r=r, eta=eta, n=n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a7fd87-924b-41b0-a505-25cac190e8cd",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d385bc3-625f-4726-a2b3-7dac659fda04",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "547edc7c-4c9b-4f47-8a61-9398fc20f79f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# split into train and test\n",
    "df_train = df_synthetic.loc[range(0,int(len(df_synthetic)/2)), :]\n",
    "# if original dataset has odd number of samples, remove 1 sample to be even\n",
    "if (len(df_synthetic) % 2 == 1):\n",
    "    df_test = df_synthetic.loc[range(int(len(df_synthetic)/2)+1, len(df_synthetic)), :]\n",
    "else:\n",
    "    df_test = df_synthetic.loc[range(int(len(df_synthetic)/2), len(df_synthetic)), :]\n",
    "    \n",
    "df_test_maj = df_test[df_test['cat'] == 1]\n",
    "df_test_min = df_test[df_test['cat'] == 0]\n",
    "\n",
    "# format data\n",
    "X_true = df_test.iloc[:, :-1].values\n",
    "y_true = df_test.iloc[:, -1].values\n",
    "\n",
    "X_true_maj = df_test_maj.iloc[:, :-1].values\n",
    "y_true_maj = df_test_maj.iloc[:, -1].values\n",
    "X_true_min = df_test_min.iloc[:, :-1].values\n",
    "y_true_min = df_test_min.iloc[:, -1].values\n",
    "\n",
    "sens_attrs_true = [df_test['cat']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce20447d-74da-4e7e-86d2-9503c49d1846",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "num1       0.000036\n",
       "num2       0.004933\n",
       "num3       0.004190\n",
       "cat        1.000000\n",
       "outcome    0.502448\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_maj.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "243e20db-d7a4-4fcb-b7e8-7813d0083b59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    5028\n",
       "0.0    4979\n",
       "Name: outcome, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_maj['outcome'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8815d5a-dce6-4054-8e1c-93f74d14770b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    2572\n",
       "1.0    2421\n",
       "Name: outcome, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_min['outcome'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1dcb2c66-8e9e-4009-9b13-ce22e553ecfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "num1      -0.026733\n",
       "num2       0.009773\n",
       "num3      -0.022018\n",
       "cat        0.000000\n",
       "outcome    0.484879\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_min.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe8e1c29-61e1-47b2-af16-a9103bd2d3fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  0\n",
      "Accuracy of Bayes Optimal Model on Ground Truth Data (Maj):  0.7557861133280128\n",
      "Accuracy of Bayes Optimal Model on Ground Truth Data (Min):  0.5992765273311897\n",
      "\n",
      "Coefs Majority:  [[-0.68071998  0.53679575  1.47038994 -0.01001945]]\n",
      "Coefs Minority:  [[ 0.50395267 -0.20259017  0.01968179  0.        ]]\n",
      "\n",
      "\n",
      "Iteration:  1\n",
      "Accuracy of Bayes Optimal Model on Ground Truth Data (Maj):  0.7566612838110618\n",
      "Accuracy of Bayes Optimal Model on Ground Truth Data (Min):  0.6103692065985861\n",
      "\n",
      "Coefs Majority:  [[-0.67684591  0.50635479  1.48939261 -0.00504894]]\n",
      "Coefs Minority:  [[ 0.49518529 -0.2294537   0.0906248   0.        ]]\n",
      "\n",
      "\n",
      "Iteration:  2\n",
      "Accuracy of Bayes Optimal Model on Ground Truth Data (Maj):  0.7575573753917703\n",
      "Accuracy of Bayes Optimal Model on Ground Truth Data (Min):  0.6128400861225288\n",
      "\n",
      "Coefs Majority:  [[-0.66178775  0.48956896  1.52763186  0.01208363]]\n",
      "Coefs Minority:  [[ 0.52768077 -0.15418474  0.10090714  0.        ]]\n",
      "\n",
      "\n",
      "Iteration:  3\n",
      "Accuracy of Bayes Optimal Model on Ground Truth Data (Maj):  0.758051689860835\n",
      "Accuracy of Bayes Optimal Model on Ground Truth Data (Min):  0.6076923076923076\n",
      "\n",
      "Coefs Majority:  [[-0.73233772  0.50813397  1.50422406 -0.0061681 ]]\n",
      "Coefs Minority:  [[ 0.52818081 -0.15094371  0.13320635  0.        ]]\n",
      "\n",
      "\n",
      "Iteration:  4\n",
      "Accuracy of Bayes Optimal Model on Ground Truth Data (Maj):  0.7570205138418642\n",
      "Accuracy of Bayes Optimal Model on Ground Truth Data (Min):  0.6010488100040339\n",
      "\n",
      "Coefs Majority:  [[-0.73133353  0.47609136  1.5006007  -0.00214757]]\n",
      "Coefs Minority:  [[ 0.49488659 -0.19960255  0.08754119  0.        ]]\n",
      "\n",
      "\n",
      "Iteration:  5\n",
      "Accuracy of Bayes Optimal Model on Ground Truth Data (Maj):  0.7571299909936956\n",
      "Accuracy of Bayes Optimal Model on Ground Truth Data (Min):  0.609346914319952\n",
      "\n",
      "Coefs Majority:  [[-0.70243405  0.49413908  1.51757326  0.00704941]]\n",
      "Coefs Minority:  [[ 0.52369743 -0.21379392  0.09490276  0.        ]]\n",
      "\n",
      "\n",
      "Iteration:  6\n",
      "Accuracy of Bayes Optimal Model on Ground Truth Data (Maj):  0.7681188516362176\n",
      "Accuracy of Bayes Optimal Model on Ground Truth Data (Min):  0.6026200873362445\n",
      "\n",
      "Coefs Majority:  [[-0.7126787   0.56540734  1.55714604 -0.01251963]]\n",
      "Coefs Minority:  [[ 0.48216525 -0.21618934  0.13686614  0.        ]]\n",
      "\n",
      "\n",
      "Iteration:  7\n",
      "Accuracy of Bayes Optimal Model on Ground Truth Data (Maj):  0.7516966067864271\n",
      "Accuracy of Bayes Optimal Model on Ground Truth Data (Min):  0.6106425702811245\n",
      "\n",
      "Coefs Majority:  [[-0.67902037  0.53936758  1.49429153  0.01929386]]\n",
      "Coefs Minority:  [[ 0.5261284  -0.22937984  0.13945376  0.        ]]\n",
      "\n",
      "\n",
      "Iteration:  8\n",
      "Accuracy of Bayes Optimal Model on Ground Truth Data (Maj):  0.7537462537462537\n",
      "Accuracy of Bayes Optimal Model on Ground Truth Data (Min):  0.6062124248496994\n",
      "\n",
      "Coefs Majority:  [[-7.22235938e-01  5.11232666e-01  1.53809457e+00 -2.89604175e-05]]\n",
      "Coefs Minority:  [[ 0.49345487 -0.22702156  0.12464045  0.        ]]\n",
      "\n",
      "\n",
      "Iteration:  9\n",
      "Accuracy of Bayes Optimal Model on Ground Truth Data (Maj):  0.7564089874294764\n",
      "Accuracy of Bayes Optimal Model on Ground Truth Data (Min):  0.5936287522973249\n",
      "\n",
      "Coefs Majority:  [[-0.72032551  0.49320008  1.47086753 -0.00220257]]\n",
      "Coefs Minority:  [[ 0.46693041 -0.18215416  0.06952383  0.        ]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    df_synthetic = true_label_generation(r=r, eta=eta, n=n)\n",
    "    df_train = df_synthetic.loc[range(0,int(len(df_synthetic)/2)), :]\n",
    "    if (len(df_synthetic) % 2 == 1):\n",
    "        df_test = df_synthetic.loc[range(int(len(df_synthetic)/2)+1, len(df_synthetic)), :]\n",
    "    else:\n",
    "        df_test = df_synthetic.loc[range(int(len(df_synthetic)/2), len(df_synthetic)), :]\n",
    "    \n",
    "    df_test_maj = df_test[df_test['cat'] == 1]\n",
    "    df_test_min = df_test[df_test['cat'] == 0]\n",
    "\n",
    "    # format data\n",
    "    X_true = df_test.iloc[:, :-1].values\n",
    "    y_true = df_test.iloc[:, -1].values\n",
    "\n",
    "    X_true_maj = df_test_maj.iloc[:, :-1].values\n",
    "    y_true_maj = df_test_maj.iloc[:, -1].values\n",
    "    X_true_min = df_test_min.iloc[:, :-1].values\n",
    "    y_true_min = df_test_min.iloc[:, -1].values\n",
    "\n",
    "    classifier_b = LogisticRegression(solver='lbfgs', random_state=42, penalty = 'l2')\n",
    "    classifier_bo = classifier_b.fit(X_true, y_true)\n",
    "    bo_pred = classifier_bo.predict(X_true)\n",
    "\n",
    "    classifier_b_maj = LogisticRegression(solver='lbfgs', random_state=42, penalty = 'l2')\n",
    "    classifier_maj = classifier_b_maj.fit(X_true_maj, y_true_maj)\n",
    "    bo_maj_pred = classifier_maj.predict(X_true_maj)\n",
    "\n",
    "    classifier_b_min = LogisticRegression(solver='lbfgs', random_state=42, penalty = 'l2')\n",
    "    classifier_min = classifier_b_min.fit(X_true_min, y_true_min)\n",
    "    bo_min_pred = classifier_min.predict(X_true_min)\n",
    "    \n",
    "    print(\"Iteration: \", i)\n",
    "\n",
    "    #print(\"\\nAccuracy of Bayes Optimal Model on Ground Truth Data: \", accuracy_score(bo_pred, y_true))\n",
    "    print(\"Accuracy of Bayes Optimal Model on Ground Truth Data (Maj): \", accuracy_score(bo_maj_pred, y_true_maj))\n",
    "    print(\"Accuracy of Bayes Optimal Model on Ground Truth Data (Min): \", accuracy_score(bo_min_pred, y_true_min))\n",
    "\n",
    "    effect_param_maj = [-0.7, 0.5, 1.5]\n",
    "    effect_param_min = [0.5, -0.2, 0.1] \n",
    "\n",
    "    print(\"\\nCoefs Majority: \", classifier_maj.coef_)\n",
    "    print(\"Coefs Minority: \", classifier_min.coef_)\n",
    "    \n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950918b3",
   "metadata": {},
   "source": [
    "# Bias Injection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a788ace-562a-4256-a853-40db73a61e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def under_sample(df_minority_positive, beta):\n",
    "    X_min = df_minority_positive.iloc[:, :].values\n",
    "    \n",
    "    # keep each example with probability beta\n",
    "    for i in range(len(X_min)):\n",
    "        if random.uniform(0,1) > beta:\n",
    "            X_min = np.delete(X_min, 0, axis=0)\n",
    "    \n",
    "    df_minority_positive = pd.DataFrame(pd.DataFrame(X_min))\n",
    "    df_minority_positive.columns = ['num1','num2','num3','cat','outcome']\n",
    "    return df_minority_positive\n",
    "\n",
    "def get_biased_data(df_train, beta):\n",
    "    df_majority = df_train[df_train['cat'] == 1]\n",
    "    df_minority = df_train[df_train['cat'] == 0]\n",
    "    \n",
    "    # unfavored group with negative label\n",
    "    df_minority_negative = df_minority[df_minority['outcome'] == 0.0]\n",
    "\n",
    "    # unfavored group with positive label (preferred)\n",
    "    df_minority_positive = df_minority[df_minority['outcome'] == 1.0]\n",
    "    \n",
    "    # data frame without positively labeled examples from minority class\n",
    "    df_total = pd.concat([df_majority, df_minority_negative])\n",
    "    \n",
    "    # under-sampling process\n",
    "    df_undersampled = under_sample(df_minority_positive, beta)\n",
    "\n",
    "    # combine undersampled and original favored class to create dataset\n",
    "    df_concat = pd.concat([df_total,df_undersampled])\n",
    "    \n",
    "    return df_concat.sample(frac=1) # permute data\n",
    "\n",
    "df_concat = get_biased_data(df_train, 0.5)\n",
    "\n",
    "# for fairness measures later\n",
    "df_sens = df_concat['cat']\n",
    "\n",
    "# format data\n",
    "X_bias = df_concat.iloc[:, :-1].values\n",
    "y_bias = df_concat.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "213427a7-8fec-4a2a-a568-439e01b6b31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Nil-Jana's Suggestions '''\n",
    "\n",
    "def transform(df, is_test = False):\n",
    "\n",
    "    sens_feat = df.iloc[:, -2].values\n",
    "    outcome = df.iloc[:, -1].values\n",
    "    num_feats = df.iloc[:, :-2].values\n",
    "\n",
    "    trans_feats = []\n",
    "    # -2 for sensitive feature and label\n",
    "    for i in range(len(df.columns) - 2):\n",
    "        num_feat = df.iloc[:, i].values\n",
    "        num_feat_transf = np.multiply(num_feat, sens_feat)\n",
    "        trans_feats += [num_feat_transf.reshape((len(df),))]\n",
    "\n",
    "\n",
    "    temp_data = np.hstack((num_feats, trans_feats[0].reshape((len(df),1)), trans_feats[1].reshape((len(df),1)), trans_feats[2].reshape((len(df),1)), outcome.reshape((len(df),1))))\n",
    "\n",
    "    df_transf = pd.DataFrame(temp_data)\n",
    "    df_transf.columns = ['num1','num2','num3', 'num1_transf','num2_transf','num3_transf','outcome']\n",
    "\n",
    "    # for fairness measures later\n",
    "    df_sens = df['cat']\n",
    "    maj_list = list(df[df['cat'] == 1].index)\n",
    "    min_list = list(df[df['cat'] == 0].index)\n",
    "    \n",
    "    for i in range(len(maj_list)):\n",
    "        maj_list[i] = maj_list[i] - len(df)\n",
    "        \n",
    "    for i in range(len(min_list)):\n",
    "        min_list[i] = min_list[i] - len(df)\n",
    "\n",
    "    # format data\n",
    "    X_bias = df_transf.iloc[:, :-1].values\n",
    "    y_bias = df_transf.iloc[:, -1].values\n",
    "    \n",
    "    if not is_test:\n",
    "        return X_bias, y_bias, df_sens\n",
    "    else:\n",
    "        return df_transf, maj_list, min_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84403b44",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f6827f",
   "metadata": {},
   "source": [
    "### Model Selection + Training (TODO: modularize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e198bb7-af19-46fa-96e0-f3b7cb155f21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nclassifier = LogisticRegression(random_state=42)\\n\\nclassifier_bias = classifier.fit(X_bias, y_bias)\\ny_pred_bias = classifier_bias.predict(X_bias)\\ny_pred_bias_on_true = classifier_bias.predict(X_true)\\n\\nclassifier_b = LogisticRegression(solver='lbfgs', random_state=42, penalty = 'l2')\\nclassifier_bo = classifier_b.fit(X_true, y_true)\\nbo_pred = classifier_bo.predict(X_true)\\n\\nclassifier_b_maj = LogisticRegression(solver='lbfgs', random_state=42, penalty = 'l2')\\nclassifier_maj = classifier_b_maj.fit(X_true_maj, y_true_maj)\\nbo_maj_pred = classifier_maj.predict(X_true_maj)\\n\\nclassifier_b_min = LogisticRegression(solver='lbfgs', random_state=42, penalty = 'l2')\\nclassifier_min = classifier_b_min.fit(X_true_min, y_true_min)\\nbo_min_pred = classifier_min.predict(X_true_min)\\n\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "classifier = LogisticRegression(random_state=42)\n",
    "\n",
    "classifier_bias = classifier.fit(X_bias, y_bias)\n",
    "y_pred_bias = classifier_bias.predict(X_bias)\n",
    "y_pred_bias_on_true = classifier_bias.predict(X_true)\n",
    "\n",
    "classifier_b = LogisticRegression(solver='lbfgs', random_state=42, penalty = 'l2')\n",
    "classifier_bo = classifier_b.fit(X_true, y_true)\n",
    "bo_pred = classifier_bo.predict(X_true)\n",
    "\n",
    "classifier_b_maj = LogisticRegression(solver='lbfgs', random_state=42, penalty = 'l2')\n",
    "classifier_maj = classifier_b_maj.fit(X_true_maj, y_true_maj)\n",
    "bo_maj_pred = classifier_maj.predict(X_true_maj)\n",
    "\n",
    "classifier_b_min = LogisticRegression(solver='lbfgs', random_state=42, penalty = 'l2')\n",
    "classifier_min = classifier_b_min.fit(X_true_min, y_true_min)\n",
    "bo_min_pred = classifier_min.predict(X_true_min)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d70210bc-f996-40bc-8956-5fa16b826986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.15947852, 0.84052148],\n",
       "       [0.09386762, 0.90613238],\n",
       "       [0.55934513, 0.44065487],\n",
       "       ...,\n",
       "       [0.51233414, 0.48766586],\n",
       "       [0.31421207, 0.68578793],\n",
       "       [0.42977412, 0.57022588]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_b_maj = LogisticRegression(solver='lbfgs', random_state=42, penalty = 'l2').fit(X_true_maj, y_true_maj)\n",
    "y_maj_pred = classifier_b_maj.predict_proba(X_true_maj)\n",
    "y_maj_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "72d79618",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-10T20:42:09.057618Z",
     "start_time": "2021-06-10T20:42:08.942574Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "******** For i = 0.05 ******\n",
      "Maj accuracy: 0.5396416905869543\n",
      "Min accuracy: 0.5084745762711864\n",
      "\n",
      "******** For i = 0.1 ******\n",
      "Maj accuracy: 0.5899237850143522\n",
      "Min accuracy: 0.5084745762711864\n",
      "\n",
      "******** For i = 0.15 ******\n",
      "Maj accuracy: 0.6356527764030486\n",
      "Min accuracy: 0.5086787829283235\n",
      "\n",
      "******** For i = 0.2 ******\n",
      "Maj accuracy: 0.6706918737008809\n",
      "Min accuracy: 0.5096998162140086\n",
      "\n",
      "******** For i = 0.25 ******\n",
      "Maj accuracy: 0.7003860239532812\n",
      "Min accuracy: 0.5158260159281193\n",
      "\n",
      "******** For i = 0.3 ******\n",
      "Maj accuracy: 0.7206770266257547\n",
      "Min accuracy: 0.5299162752705738\n",
      "\n",
      "******** For i = 0.35 ******\n",
      "Maj accuracy: 0.7387904582797189\n",
      "Min accuracy: 0.5546252807841535\n",
      "\n",
      "******** For i = 0.4 ******\n",
      "Maj accuracy: 0.7473027813520736\n",
      "Min accuracy: 0.5756585664692669\n",
      "\n",
      "******** For i = 0.45 ******\n",
      "Maj accuracy: 0.7519548648916163\n",
      "Min accuracy: 0.594241372268736\n",
      "\n",
      "******** For i = 0.5 ******\n",
      "Maj accuracy: 0.7564089874294764\n",
      "Min accuracy: 0.5936287522973249\n",
      "\n",
      "******** For i = 0.55 ******\n",
      "Maj accuracy: 0.7571018509353657\n",
      "Min accuracy: 0.5852562793547069\n",
      "\n",
      "******** For i = 0.6 ******\n",
      "Maj accuracy: 0.7496783133722656\n",
      "Min accuracy: 0.5627935470696345\n",
      "\n",
      "******** For i = 0.65 ******\n",
      "Maj accuracy: 0.7374047312679403\n",
      "Min accuracy: 0.5368593016132326\n",
      "\n",
      "******** For i = 0.7 ******\n",
      "Maj accuracy: 0.7216668316341681\n",
      "Min accuracy: 0.5115376761282417\n",
      "\n",
      "******** For i = 0.75 ******\n",
      "Maj accuracy: 0.6998911214490745\n",
      "Min accuracy: 0.49846845007147234\n",
      "\n",
      "******** For i = 0.8 ******\n",
      "Maj accuracy: 0.6690092051865782\n",
      "Min accuracy: 0.49275066367163567\n",
      "\n",
      "******** For i = 0.85 ******\n",
      "Maj accuracy: 0.6337721468870633\n",
      "Min accuracy: 0.4915254237288136\n",
      "\n",
      "******** For i = 0.9 ******\n",
      "Maj accuracy: 0.5894288825101455\n",
      "Min accuracy: 0.4915254237288136\n",
      "\n",
      "******** For i = 0.95 ******\n",
      "Maj accuracy: 0.5382559635751757\n",
      "Min accuracy: 0.4915254237288136\n",
      "\n",
      "******** For i = 0.99 ******\n",
      "Maj accuracy: 0.502524002771454\n",
      "Min accuracy: 0.4915254237288136\n"
     ]
    }
   ],
   "source": [
    "classifier = LogisticRegression(random_state=42)\n",
    "\n",
    "'''\n",
    "classifier_bias = classifier.fit(X_bias, y_bias)\n",
    "y_pred_bias = classifier_bias.predict(X_bias)\n",
    "y_pred_bias_on_true = classifier_bias.predict(X_true)\n",
    "\n",
    "classifier_b = LogisticRegression(solver='lbfgs', random_state=42, penalty = 'l2')\n",
    "classifier_bo = classifier_b.fit(X_true, y_true)\n",
    "bo_pred = classifier_bo.predict(X_true)\n",
    "'''\n",
    "\n",
    "classifier_b_maj = LogisticRegression(solver='lbfgs', random_state=42, penalty = 'l2').fit(X_true_maj, y_true_maj)\n",
    "classifier_b_min = LogisticRegression(solver='lbfgs', random_state=42, penalty = 'l2').fit(X_true_min, y_true_min)\n",
    "\n",
    "threshold_list = [0.05,0.1,0.15,0.2,0.25,0.3,0.35,0.4,0.45,0.5,0.55,0.6,0.65,.7,.75,.8,.85,.9,.95,.99]\n",
    "for i in threshold_list:\n",
    "    print ('\\n******** For i = {} ******'.format(i))\n",
    "    pred_proba_df_maj = pd.DataFrame(classifier_b_maj.predict_proba(X_true_maj))\n",
    "    pred_proba_df_min = pd.DataFrame(classifier_b_min.predict_proba(X_true_min))\n",
    "    Y_test_pred_maj = pred_proba_df_maj.applymap(lambda x: 1 if x>i else 0)\n",
    "    Y_test_pred_min = pred_proba_df_min.applymap(lambda x: 1 if x>i else 0)\n",
    "    test_accuracy_maj = accuracy_score(y_true_maj, Y_test_pred_maj.iloc[:,1].values.reshape(y_true_maj.shape))\n",
    "    test_accuracy_min = accuracy_score(y_true_min, Y_test_pred_min.iloc[:,1].values.reshape(y_true_min.shape))\n",
    "    print('Maj accuracy: {}'.format(test_accuracy_maj))\n",
    "    print('Min accuracy: {}'.format(test_accuracy_min))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff477ccd",
   "metadata": {},
   "source": [
    "### Model Performance (TODO: modularize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "adf0a2b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-10T20:42:09.231352Z",
     "start_time": "2021-06-10T20:42:09.225108Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthetic Data\n",
      "\n",
      "Accuracy of Bayes Optimal Model on Ground Truth Data (Maj):  0.7564089874294764\n",
      "Accuracy of Bayes Optimal Model on Ground Truth Data (Min):  0.5936287522973249\n",
      "\n",
      "Coefs Majority:  [[-0.72032551  0.49320008  1.47086753 -0.00220257]]\n",
      "Coefs Minority:  [[ 0.46693041 -0.18215416  0.06952383  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Synthetic Data\\n\")\n",
    "\n",
    "#print(\"Accuracy of Biased Model on Biased Data: \", accuracy_score(y_pred_bias, y_bias))\n",
    "#print(\"Accuracy of Biased Model on Ground Truth Data: \", accuracy_score(y_pred_bias_on_true, y_true))\n",
    "\n",
    "#print(\"\\nAccuracy of Bayes Optimal Model on Ground Truth Data: \", accuracy_score(bo_pred, y_true))\n",
    "print(\"Accuracy of Bayes Optimal Model on Ground Truth Data (Maj): \", accuracy_score(bo_maj_pred, y_true_maj))\n",
    "print(\"Accuracy of Bayes Optimal Model on Ground Truth Data (Min): \", accuracy_score(bo_min_pred, y_true_min))\n",
    "\n",
    "effect_param_maj = [-0.7, 0.5, 1.5]\n",
    "effect_param_min = [0.5, -0.2, 0.1] \n",
    "\n",
    "print(\"\\nCoefs Majority: \", classifier_maj.coef_)\n",
    "print(\"Coefs Minority: \", classifier_min.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7ea20d",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f17d7a-7138-479b-87f7-ff45e561eb97",
   "metadata": {},
   "source": [
    "### Error Bars with Multiple Iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7cdc3dd6-a00b-4e1d-8177-86130db9a557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if verbose, shows \"Finished iteration: ... \"\n",
    "def tradeoff_visualization_error(classifier, X_true, y_true, df_train,\n",
    "                           sensitive_feature = \"cat\",\n",
    "                           apply_fairness = False, verbose = False, num_iters = 10):\n",
    "    \n",
    "    total_accuracy_on_true = []\n",
    "    total_accuracy_on_true_maj = []\n",
    "    total_accuracy_on_true_min = []\n",
    "    total_accuracy_on_biased = []\n",
    "    total_accuracy_on_true_mitigated = []\n",
    "    total_accuracy_on_true_mitigated_maj = []\n",
    "    total_accuracy_on_true_mitigated_min = []\n",
    "    total_accuracy_on_biased_mitigated = []\n",
    "    total_bayes_accuracy_on_true = []\n",
    "    total_bayes_accuracy_on_true_maj = []\n",
    "    total_bayes_accuracy_on_true_min = []\n",
    "    bayes_accuracy_on_true = []\n",
    "    bayes_accuracy_on_true_maj = []\n",
    "    bayes_accuracy_on_true_min = []\n",
    "    \n",
    "    for i in range(num_iters):\n",
    "    \n",
    "        # 0 to 1 in increments of 0.1\n",
    "        bias_amts = np.divide(list(range(10,-1,-1)),10)\n",
    "        accuracy_on_true = []\n",
    "        accuracy_on_true_maj = []\n",
    "        accuracy_on_true_min = []\n",
    "        accuracy_on_biased = []\n",
    "        accuracy_on_true_mitigated = []\n",
    "        accuracy_on_true_mitigated_maj = []\n",
    "        accuracy_on_true_mitigated_min = []\n",
    "        accuracy_on_biased_mitigated = []\n",
    "        bayes_temp = []\n",
    "        bayes_temp_maj = []\n",
    "        bayes_temp_min = []\n",
    "\n",
    "        count = 0\n",
    "        \n",
    "        df_synthetic = true_label_generation(r=r, eta=eta, n=n)\n",
    "        \n",
    "        # split into train and test\n",
    "        df_train = df_synthetic.loc[range(0,int(len(df_synthetic)/2)), :]\n",
    "        # if original dataset has odd number of samples, remove 1 sample to be even\n",
    "        if (len(df_synthetic) % 2 == 1):\n",
    "            df_test = df_synthetic.loc[range(int(len(df_synthetic)/2)+1, len(df_synthetic)), :]\n",
    "        else:\n",
    "            df_test = df_synthetic.loc[range(int(len(df_synthetic)/2), len(df_synthetic)), :]\n",
    "        \n",
    "        #df_test_transf = df_test\n",
    "        df_test_transf, maj_list, min_list = transform(df_test, True)\n",
    "            \n",
    "        df_test_maj = df_test_transf.loc[maj_list]\n",
    "        #df_test_maj = df_test[df_test['cat'] == 1]\n",
    "        df_test_min = df_test_transf.loc[min_list]\n",
    "        #df_test_min = df_test[df_test['cat'] == 0]\n",
    "\n",
    "        # format data\n",
    "        X_true = df_test_transf.iloc[:, :-1].values\n",
    "        y_true = df_test_transf.iloc[:, -1].values\n",
    "        X_true_maj = df_test_maj.iloc[:, :-1].values\n",
    "        y_true_maj = df_test_maj.iloc[:, -1].values\n",
    "        X_true_min = df_test_min.iloc[:, :-1].values\n",
    "        y_true_min = df_test_min.iloc[:, -1].values\n",
    "        \n",
    "        # bayes optimal classifier(s) accuracy on ground truth data\n",
    "\n",
    "        sens_attrs_true = [df_test['cat']]\n",
    "\n",
    "        for beta in bias_amts:\n",
    "            \n",
    "            if i == 0: print(\"Beta: \", beta, '\\n')\n",
    "\n",
    "            df_train_copy = df_train.copy()\n",
    "\n",
    "            df_majority = df_train_copy[df_train_copy['cat'] == 1]\n",
    "            df_minority = df_train_copy[df_train_copy['cat'] == 0]\n",
    "\n",
    "            # unfavored group with negative label\n",
    "            df_minority_negative = df_minority[df_minority['outcome'] == 0.0]\n",
    "\n",
    "            # unfavored group with positive label (preferred)\n",
    "            df_minority_positive = df_minority[df_minority['outcome'] == 1.0]\n",
    "\n",
    "            # data frame without positively labeled examples from minority class\n",
    "            df_total = pd.concat([df_majority, df_minority_negative])\n",
    "\n",
    "            # under-sampling process\n",
    "            df_undersampled = under_sample(df_minority_positive, beta)\n",
    "            #print(\"Num Minority Pos: \", len(df_undersampled))\n",
    "\n",
    "            # combine undersampled and original favored class to create dataset\n",
    "            df_concat = pd.concat([df_total,df_undersampled])\n",
    "\n",
    "            # format data\n",
    "            X_bias_true, y_bias_true, df_sens = transform(df_concat)\n",
    "            #X_bias_true, y_bias_true, df_sens = df_concat.iloc[:, :-1].values, df_concat.iloc[:, -1].values, df_concat['cat']\n",
    "\n",
    "            classifier_bias = classifier.fit(X_bias_true, y_bias_true)\n",
    "            if i == 0: print(\"Model + No Intervention Coefs: \", classifier_bias.coef_)\n",
    "            \n",
    "            # bayes optimal\n",
    "            classifier_b = clone(classifier).fit(X_true, y_true)\n",
    "            bo_pred = classifier_b.predict(X_true)\n",
    "            \n",
    "            classifier_b_maj = clone(classifier).fit(X_true_maj, y_true_maj)\n",
    "            bo_maj_pred = classifier_b_maj.predict(X_true_maj)\n",
    "            if i == 0: print(\"BO Majority Coefs: \", classifier_b_maj.coef_)\n",
    "            \n",
    "            classifier_b_min = clone(classifier).fit(X_true_min, y_true_min)\n",
    "            bo_min_pred = classifier_b_min.predict(X_true_min)\n",
    "            if i == 0: print(\"BO Minority Coefs: \", classifier_b_min.coef_)\n",
    "                        \n",
    "            bayes_temp.append(accuracy_score(bo_pred, y_true))\n",
    "            bayes_temp_maj.append(accuracy_score(bo_maj_pred, y_true_maj))\n",
    "            bayes_temp_min.append(accuracy_score(bo_min_pred, y_true_min))\n",
    "            \n",
    "            if beta == 1.0: \n",
    "                print(\"BO Majority Accuracy: \", accuracy_score(bo_maj_pred, y_true_maj))\n",
    "                print(\"BO Minority Accuracy: \", accuracy_score(bo_min_pred, y_true_min))\n",
    "                \n",
    "\n",
    "            if apply_fairness:\n",
    "                constraint = EqualizedOdds()\n",
    "                classifier_mitigated_bias = GridSearch(clone(classifier_bias), constraint)\n",
    "                #classifier_mitigated_bias = ExponentiatedGradient(clone(classifier_bias), constraint)\n",
    "                classifier_mitigated_bias.fit(X_bias_true, y_bias_true, sensitive_features = df_sens)\n",
    "\n",
    "                # testing on biased data WITH fairness intervention\n",
    "                y_pred_mitigated_bias = classifier_mitigated_bias.predict(X_bias_true)\n",
    "\n",
    "                # testing on GT data WITH fairness intervention\n",
    "                y_pred_mitigated_bias_on_true = classifier_mitigated_bias.predict(X_true)\n",
    "                y_pred_mitigated_bias_on_true_maj = classifier_mitigated_bias.predict(X_true_maj)\n",
    "                y_pred_mitigated_bias_on_true_min = classifier_mitigated_bias.predict(X_true_min)\n",
    "\n",
    "            # testing on biased data withOUT fairness intervention\n",
    "            y_pred_bias = classifier_bias.predict(X_bias_true)\n",
    "\n",
    "            # testing on GT data withOUT fairness intervention\n",
    "            y_pred_bias_on_true = classifier_bias.predict(X_true)\n",
    "            y_pred_bias_on_true_maj = classifier_bias.predict(X_true_maj)\n",
    "            y_pred_bias_on_true_min = classifier_bias.predict(X_true_min)\n",
    "\n",
    "            # model performance\n",
    "\n",
    "            if apply_fairness:\n",
    "                # on biased data\n",
    "                acc_bias_mitigated = accuracy_score(y_pred=y_pred_mitigated_bias, y_true=y_bias_true)\n",
    "                accuracy_on_biased_mitigated.append(acc_bias_mitigated)\n",
    "\n",
    "                # on GT data\n",
    "                acc_bias_mitigated_on_true = accuracy_score(y_pred=y_pred_mitigated_bias_on_true, y_true=y_true)\n",
    "                accuracy_on_true_mitigated.append(acc_bias_mitigated_on_true)\n",
    "                \n",
    "                acc_bias_mitigated_on_true_maj = accuracy_score(y_pred=y_pred_mitigated_bias_on_true_maj, y_true=y_true_maj)\n",
    "                accuracy_on_true_mitigated_maj.append(acc_bias_mitigated_on_true_maj)\n",
    "                print(\"Model on GT + Intervention (Maj):\", acc_bias_mitigated_on_true_maj)\n",
    "                \n",
    "                acc_bias_mitigated_on_true_min = accuracy_score(y_pred=y_pred_mitigated_bias_on_true_min, y_true=y_true_min)\n",
    "                accuracy_on_true_mitigated_min.append(acc_bias_mitigated_on_true_min)\n",
    "                print(\"Model on GT + Intervention (Min):\", acc_bias_mitigated_on_true_min)\n",
    "\n",
    "            # on biased data\n",
    "            acc_bias = accuracy_score(y_pred=y_pred_bias, y_true=y_bias_true)\n",
    "            accuracy_on_biased.append(acc_bias)\n",
    "            \n",
    "            acc_bias_on_true_maj = accuracy_score(y_pred=y_pred_bias_on_true_maj, y_true=y_true_maj)\n",
    "            accuracy_on_true_maj.append(acc_bias_on_true_maj)\n",
    "            print(\"Model on GT + NO Intervention (Maj):\", acc_bias_on_true_maj)\n",
    "\n",
    "            acc_bias_on_true_min = accuracy_score(y_pred=y_pred_bias_on_true_min, y_true=y_true_min)\n",
    "            accuracy_on_true_min.append(acc_bias_on_true_min)\n",
    "            print(\"Model on GT + NO Intervention (Min):\", acc_bias_on_true_min)\n",
    "            \n",
    "            # on GT data\n",
    "            acc_bias_on_true = accuracy_score(y_pred=y_pred_bias_on_true, y_true=y_true)\n",
    "            accuracy_on_true.append(acc_bias_on_true)\n",
    "\n",
    "            if verbose:\n",
    "                print(\"Finished Iteration: \", count)\n",
    "                count +=1\n",
    "\n",
    "            # fail-safe\n",
    "            if count > 30:\n",
    "                break\n",
    "        \n",
    "        total_accuracy_on_biased.append(accuracy_on_biased)\n",
    "        total_accuracy_on_biased_mitigated.append(accuracy_on_biased_mitigated)\n",
    "        total_accuracy_on_true.append(accuracy_on_true)\n",
    "        total_accuracy_on_true_maj.append(accuracy_on_true_maj)\n",
    "        total_accuracy_on_true_min.append(accuracy_on_true_min)\n",
    "        total_accuracy_on_true_mitigated.append(accuracy_on_true_mitigated)\n",
    "        total_accuracy_on_true_mitigated_maj.append(accuracy_on_true_mitigated_maj)\n",
    "        total_accuracy_on_true_mitigated_min.append(accuracy_on_true_mitigated_min)\n",
    "        \n",
    "        total_bayes_accuracy_on_true.append(bayes_temp)\n",
    "        total_bayes_accuracy_on_true_maj.append(bayes_temp_maj)\n",
    "        total_bayes_accuracy_on_true_min.append(bayes_temp_min)\n",
    "        \n",
    "        if verbose:\n",
    "                print(\"Finished Total Iteration: \", i+1)\n",
    "    \n",
    "        \n",
    "    mean_biased = np.mean(total_accuracy_on_biased, axis = 0)\n",
    "    mean_biased_mitigated = np.mean(total_accuracy_on_biased_mitigated, axis = 0)\n",
    "    mean_true = np.mean(total_accuracy_on_true, axis = 0)\n",
    "    mean_true_maj = np.mean(total_accuracy_on_true_maj, axis = 0)\n",
    "    mean_true_min = np.mean(total_accuracy_on_true_min, axis = 0)\n",
    "    mean_true_mitigated = np.mean(total_accuracy_on_true_mitigated, axis = 0)\n",
    "    mean_true_mitigated_maj = np.mean(total_accuracy_on_true_mitigated_maj, axis = 0)\n",
    "    mean_true_mitigated_min = np.mean(total_accuracy_on_true_mitigated_min, axis = 0)\n",
    "    \n",
    "    mean_bayes_accuracy_on_true = np.mean(total_bayes_accuracy_on_true, axis = 0)\n",
    "    mean_bayes_accuracy_on_true_maj = np.mean(total_bayes_accuracy_on_true_maj, axis = 0)\n",
    "    mean_bayes_accuracy_on_true_min = np.mean(total_bayes_accuracy_on_true_min, axis = 0) \n",
    "    \n",
    "    y_err_biased = np.std(total_accuracy_on_biased, axis = 0)\n",
    "    y_err_biased_mitigated = np.std(total_accuracy_on_biased_mitigated, axis = 0)\n",
    "    y_err_true = np.std(total_accuracy_on_true, axis = 0)\n",
    "    y_err_true_maj = np.std(total_accuracy_on_true_maj, axis = 0)\n",
    "    y_err_true_min = np.std(total_accuracy_on_true_min, axis = 0)\n",
    "    y_err_true_mitigated = np.std(total_accuracy_on_true_mitigated, axis = 0)\n",
    "    y_err_true_mitigated_maj = np.std(total_accuracy_on_true_mitigated_maj, axis = 0)\n",
    "    y_err_true_mitigated_min = np.std(total_accuracy_on_true_mitigated_min, axis = 0)\n",
    "\n",
    "\n",
    "    return bias_amts, mean_biased, mean_true, \\\n",
    "           mean_biased_mitigated, mean_true_mitigated, y_err_biased, \\\n",
    "           y_err_true, y_err_biased_mitigated, y_err_true_mitigated, \\\n",
    "           mean_true_maj, mean_true_min, \\\n",
    "           mean_true_mitigated_maj, mean_true_mitigated_min, \\\n",
    "           y_err_true_maj, y_err_true_min, \\\n",
    "           y_err_true_mitigated_maj, y_err_true_mitigated_min, \\\n",
    "           mean_bayes_accuracy_on_true, mean_bayes_accuracy_on_true_maj, \\\n",
    "           mean_bayes_accuracy_on_true_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "99bfd23f-6f40-45d1-a77f-e93d9b460459",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_visualizations(bias_amts, accuracy_on_biased = [], accuracy_on_true = [],\n",
    "                            accuracy_on_biased_mitigated = [],\n",
    "                            accuracy_on_true_mitigated = [], fairness = False):\n",
    "    plt.figure(figsize=(10,7))\n",
    "    if fairness:\n",
    "        plt.plot(bias_amts, accuracy_on_true_mitigated, label = 'Ground Truth')\n",
    "        plt.plot(bias_amts, accuracy_on_biased_mitigated, label = 'Biased Data')\n",
    "        plt.xlim(1.05, -0.05)\n",
    "        plt.xlabel(\"Beta Value\")\n",
    "        plt.ylabel(\"Accuracy Score\")\n",
    "        plt.title(\"Biased Model Accuracy\")\n",
    "        plt.legend()\n",
    "\n",
    "        plt.show()\n",
    "        \n",
    "    else:\n",
    "        plt.plot(bias_amts, accuracy_on_true, label = 'Ground Truth')\n",
    "        plt.plot(bias_amts, accuracy_on_biased, label = 'Biased Data')\n",
    "        plt.xlim(1.05, -0.05)\n",
    "        plt.xlabel(\"Beta Value\")\n",
    "        plt.ylabel(\"Accuracy Score\")\n",
    "        plt.title(\"Biased Model Accuracy\")\n",
    "        plt.legend()\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4d884d65-9fac-4e54-aafa-d3fc41b627b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_visualizations(bias_amts, mean_biased, mean_true,\n",
    "                        mean_biased_mitigated, mean_true_mitigated):\n",
    "    plt.figure(figsize=(10,7))\n",
    "    plt.errorbar(bias_amts, mean_biased, yerr= y_err_biased, label = 'Tested On Biased Data + No Fairness Intervention', color = \"red\")\n",
    "    plt.errorbar(bias_amts, mean_biased_mitigated, yerr= y_err_biased_mitigated, label = 'Tested On Biased Data + Fairness Intervention', color = \"green\")\n",
    "    plt.errorbar(bias_amts, mean_true, yerr= y_err_true, label = 'Tested On Ground Truth + No Fairness Intervention', color = \"blue\")\n",
    "    plt.errorbar(bias_amts, mean_true_mitigated, yerr= y_err_true_mitigated, label = 'Tested On Ground Truth + Fairness Intervention', color = \"purple\")\n",
    "    #plt.plot(bias_amts, bayes_accuracy_on_biased, label = 'Bayes Optimal Model On Biased Data', color = \"black\")\n",
    "    #plt.axhline(y = bayes_optimal_accuracy(df_test), label = \"Bayes Optimal Model On Ground Truth Data\", color = \"pink\")\n",
    "    plt.xlim(1.05, -0.05)\n",
    "    plt.xlabel(\"Beta Value\")\n",
    "    plt.ylabel(\"Accuracy Score\")\n",
    "    plt.title(\"Accuracy of Biased Model (trained on biased data)\")\n",
    "    #plt.legend(loc = 1)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "41379f6f-9cc4-4ab8-bf1c-5fd3dd0164ae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beta:  1.0 \n",
      "\n",
      "Model + No Intervention Coefs:  [[ 0.50159191 -0.2073284   0.08738969 -1.22984136  0.70576484  1.51235551]]\n",
      "BO Majority Coefs:  [[-0.38152842  0.2734388   0.76405654 -0.38152842  0.2734388   0.76405654]]\n",
      "BO Minority Coefs:  [[ 0.51366673 -0.18688422  0.12275201  0.          0.          0.        ]]\n",
      "BO Majority Accuracy:  0.7629093831625477\n",
      "BO Minority Accuracy:  0.605033690051526\n",
      "Model on GT + Intervention (Maj): 0.7623066104078763\n",
      "Model on GT + Intervention (Min): 0.6070154577883472\n",
      "Model on GT + NO Intervention (Maj): 0.7623066104078763\n",
      "Model on GT + NO Intervention (Min): 0.6070154577883472\n",
      "Finished Iteration:  0\n",
      "Beta:  0.9 \n",
      "\n",
      "Model + No Intervention Coefs:  [[ 0.49886144 -0.20468032  0.09033455 -1.22742607  0.70331853  1.50976064]]\n",
      "BO Majority Coefs:  [[-0.38152842  0.2734388   0.76405654 -0.38152842  0.2734388   0.76405654]]\n",
      "BO Minority Coefs:  [[ 0.51366673 -0.18688422  0.12275201  0.          0.          0.        ]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-1a911618f801>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m tradeoff_visualization_error(classifier, X_true=X_true, y_true=y_true, \\\n\u001b[1;32m     16\u001b[0m                        \u001b[0mdf_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msensitive_feature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cat\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m                        apply_fairness=True,verbose=True, num_iters=10)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-31-446b264182a8>\u001b[0m in \u001b[0;36mtradeoff_visualization_error\u001b[0;34m(classifier, X_true, y_true, df_train, sensitive_feature, apply_fairness, verbose, num_iters)\u001b[0m\n\u001b[1;32m    124\u001b[0m                 \u001b[0mclassifier_mitigated_bias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier_bias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstraint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m                 \u001b[0;31m#classifier_mitigated_bias = ExponentiatedGradient(clone(classifier_bias), constraint)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m                 \u001b[0mclassifier_mitigated_bias\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_bias_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_bias_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msensitive_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_sens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m                 \u001b[0;31m# testing on biased data WITH fairness intervention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/fairlearn/reductions/_grid_search/grid_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0mlambda_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Obtaining weights\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m             \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstraints\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigned_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlambda_vec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mobjective_in_the_span\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m                 \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mobjective\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigned_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/fairlearn/reductions/_moments/utility_parity.py\u001b[0m in \u001b[0;36msigned_weights\u001b[0;34m(self, lambda_vec)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0madjust\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlambda_event\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlambda_group_event\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         signed_weights = self.tags.apply(\n\u001b[0;32m--> 257\u001b[0;31m             \u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_EVENT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0madjust\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_EVENT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_GROUP_ID\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m         )\n\u001b[1;32m    259\u001b[0m         \u001b[0mutility_diff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutilities\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutilities\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwds)\u001b[0m\n\u001b[1;32m   6876\u001b[0m             \u001b[0mkwds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6877\u001b[0m         )\n\u001b[0;32m-> 6878\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6880\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapplymap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"DataFrame\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_empty_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m                 result = libreduction.compute_reduction(\n\u001b[0;32m--> 296\u001b[0;31m                     \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdummy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdummy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 )\n\u001b[1;32m    298\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/reduction.pyx\u001b[0m in \u001b[0;36mpandas._libs.reduction.compute_reduction\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/reduction.pyx\u001b[0m in \u001b[0;36mpandas._libs.reduction.Reducer.get_result\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/fairlearn/reductions/_moments/utility_parity.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0madjust\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlambda_event\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlambda_group_event\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         signed_weights = self.tags.apply(\n\u001b[0;32m--> 257\u001b[0;31m             \u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_EVENT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0madjust\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_EVENT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_GROUP_ID\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m         )\n\u001b[1;32m    259\u001b[0m         \u001b[0mutility_diff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutilities\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutilities\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    866\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    869\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "classifier = LogisticRegression(solver = 'lbfgs', random_state = 42, penalty = 'none')\n",
    "\n",
    "effect_param_maj = [-0.7, 0.5, 1.5]\n",
    "effect_param_min = [0.5, -0.2, 0.1]\n",
    "\n",
    "bias_amts, mean_biased, mean_true, \\\n",
    "           mean_biased_mitigated, mean_true_mitigated, y_err_biased, \\\n",
    "           y_err_true, y_err_biased_mitigated, y_err_true_mitigated, \\\n",
    "           mean_true_maj, mean_true_min, \\\n",
    "           mean_true_mitigated_maj, mean_true_mitigated_min, \\\n",
    "           y_err_true_maj, y_err_true_min, \\\n",
    "           y_err_true_mitigated_maj, y_err_true_mitigated_min, \\\n",
    "           mean_bayes_accuracy_on_true, mean_bayes_accuracy_on_true_maj, \\\n",
    "           mean_bayes_accuracy_on_true_min = \\\n",
    "tradeoff_visualization_error(classifier, X_true=X_true, y_true=y_true, \\\n",
    "                       df_train=df_train, sensitive_feature=\"cat\", \\\n",
    "                       apply_fairness=True,verbose=True, num_iters=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f906e9-9db4-40e2-ab2b-8b46ac65858f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "plt.errorbar(bias_amts, mean_true_mitigated_maj, yerr= y_err_true_mitigated_maj, label = 'Tested On Ground Truth + Intervention (Majority)', color = \"purple\")\n",
    "plt.errorbar(bias_amts, mean_true_mitigated_min, yerr= y_err_true_mitigated_min, label = 'Tested On Ground Truth + Intervention (Minority)', color = \"blue\")\n",
    "plt.errorbar(bias_amts, mean_true_maj, yerr= y_err_true_mitigated_maj, label = 'Tested On Ground Truth + NO Intervention (Majority)', color = \"pink\")\n",
    "plt.errorbar(bias_amts, mean_true_min, yerr= y_err_true_mitigated_min, label = 'Tested On Ground Truth + NO Intervention (Minority)', color = \"black\")\n",
    "plt.errorbar(bias_amts, mean_bayes_accuracy_on_true_maj, label = 'Bayes Optimal (Majority)', color = 'red')\n",
    "plt.errorbar(bias_amts, mean_bayes_accuracy_on_true_min, label = 'Bayes Optimal (Minority)', color = 'green')\n",
    "plt.legend()\n",
    "plt.xlim(1.05, -0.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f95dca7-da5e-45fe-be62-0edc4e3164ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_visualizations(bias_amts, mean_biased, mean_true,\n",
    "                    mean_biased_mitigated, mean_true_mitigated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d326e6-adbb-49ec-afc6-680dc15e0ecf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
